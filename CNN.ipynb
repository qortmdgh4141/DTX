{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "nLN6gT2LMv02"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOnATwCygOj0gEglhnzmINK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qortmdgh4141/Digital-Therapeutics-Platform-Development/blob/master/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zhus7ufrKymU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Package Imports and Shared Function Definitions"
      ],
      "metadata": {
        "id": "S39k4OdtsbP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import initializers\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Dropout, Conv3D, MaxPooling3D, MaxPooling2D, Conv2D, BatchNormalization, Conv3DTranspose, Permute, Activation, LeakyReLU\n",
        "from keras import regularizers\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from tensorflow import keras\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "4Cy0miDbZFhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_dir_path(dir_path):\n",
        "    split_path = dir_path.split('/')\n",
        "    feature = split_path[-2]  # 맨 오른쪽에서 두번째에 있는 \"distance\"\n",
        "    feature_train_test = split_path[-1]  # 맨 오른쪽 첫번째에 있는 문자열 \"distance(1&5-3)\"\n",
        "\n",
        "    extracted = feature_train_test[feature_train_test.find(\"(\")+1 : feature_train_test.find(\")\")]  # \"()\" 안의 문자열 \"1&5-3\"\n",
        "    split_extracted = extracted.split(\"-\")\n",
        "    train_part = split_extracted[0]  # \"1&5\"\n",
        "    test_part = split_extracted[1]  # \"3\"\n",
        "\n",
        "    feature_train = 'train_' + feature + \"(\" + train_part + \")\"\n",
        "    feature_test = 'test_' + feature + \"(\" + test_part + \")\"\n",
        "\n",
        "    train_dir_path = os.path.join(dir_path, feature_train)\n",
        "    test_dir_path = os.path.join(dir_path, feature_test)\n",
        "\n",
        "    return train_dir_path, test_dir_path, feature_train_test\n",
        "    \n",
        "def plot_loss_and_accuracy(train_loss, val_loss, train_acc, val_acc, model_name):\n",
        "    epochs = range(1, len(train_loss) + 1)\n",
        "    \n",
        "    plt.figure(figsize=(12, 6))\n",
        "    \n",
        "    # Loss 그래프\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
        "    plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "    plt.title(f'{model_name} Model - Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    \n",
        "    # Accuracy 그래프\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(epochs, train_acc, 'b', label='Training Accuracy')\n",
        "    plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "    plt.title(f'{model_name} Model - Training and Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Z_kqkABrrJbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the CNN Classifier Class"
      ],
      "metadata": {
        "id": "1uUSh8UHQ13u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class cnn_clf:\n",
        "    def __init__(self, train_dir_path, test_dir_path):\n",
        "        self.train_dir_path = train_dir_path\n",
        "        self.test_dir_path = test_dir_path\n",
        "\n",
        "    def main(self, augmentation, total_angle_num, angle_interval, element):\n",
        "        x_train, y_train = self.load_dataset(dir_path=self.train_dir_path, mode=\"TRAIN\", shuffle=True)\n",
        "        x_test, y_test = self.load_dataset(dir_path=self.test_dir_path, mode=\"TEST\", shuffle=False)\n",
        "\n",
        "        x_train = self.feature_scaling(x_train, norm=False, std=True, with_mean=True)\n",
        "        x_test = self.feature_scaling(x_test, norm=False, std=True, with_mean=True)\n",
        "\n",
        "        if augmentation == True:\n",
        "            x_train, y_train, augment_num_angles = self.augment_data(x_train, y_train, shuffle=True)\n",
        "            x_test, y_test, augment_num_angles = self.augment_data(x_test, y_test, shuffle=False)\n",
        "        else:\n",
        "            augment_num_angles = 1\n",
        "\n",
        "        if angle_interval != 10:\n",
        "            x_train = self.reshape_by_angle_interval(x_train, total_angle_num=total_angle_num, angle_interval=angle_interval)\n",
        "            x_test = self.reshape_by_angle_interval(x_test, total_angle_num=total_angle_num, angle_interval=angle_interval)\n",
        "\n",
        "        cnn_result, train_val_score, cnn_model  = self.train_test_cnn(x_train, y_train, x_test, y_test, element, augment_num_angles)\n",
        "\n",
        "        return cnn_result, train_val_score, cnn_model \n",
        "\n",
        "    def load_dataset(self, dir_path, mode, shuffle):\n",
        "        x_train_list = []\n",
        "        y_train = np.array([])\n",
        "\n",
        "        if shuffle == True:\n",
        "            random.seed(42)\n",
        "            sample_size = len(os.listdir(dir_path))\n",
        "            population = list(range(sample_size))\n",
        "            samples_num = random.sample(population, sample_size)\n",
        "        else :\n",
        "            sample_size = len(os.listdir(dir_path))\n",
        "            samples_num = list(range(sample_size))\n",
        "\n",
        "        for num in samples_num:\n",
        "            loaded = np.load(f\"{dir_path}/{mode}_({num}).npz\")\n",
        "            data = loaded[\"data\"]\n",
        "            label = loaded[\"label\"]\n",
        "\n",
        "            x_train_list.append(data)\n",
        "            y_train = np.concatenate([y_train, label])\n",
        "\n",
        "        x_train = np.stack(x_train_list, axis=0).astype(np.float32)\n",
        "        y_train = y_train.astype(np.float32)\n",
        "\n",
        "        return x_train, y_train\n",
        "\n",
        "    def feature_scaling(self, data, norm, std, with_mean):\n",
        "        if std == True:\n",
        "            if with_mean==True:\n",
        "                mean = np.mean(data, axis=tuple(range(data.ndim)), keepdims=True)\n",
        "                std = np.std(data, axis=tuple(range(data.ndim)), keepdims=True)\n",
        "                data = (data - mean) / std\n",
        "            else:\n",
        "                std = np.std(data, axis=tuple(range(data.ndim)), keepdims=True)\n",
        "                data = data / std\n",
        "        elif norm == True:\n",
        "            min = data.min()\n",
        "            max = data.max()\n",
        "            data = (data - min) / (max - min)\n",
        "\n",
        "        return data\n",
        "\n",
        "    def augment_data(self, x_data, y_data, shuffle):\n",
        "        num_samples = x_data.shape[0]  # 배치 사이즈\n",
        "        num_angles = x_data.shape[1]  # 각도의 개수\n",
        "\n",
        "        # 어규멘테이션된 데이터를 저장할 변수 초기화\n",
        "        augmented_x_data = np.zeros((num_samples * num_angles, *x_data.shape[1:]), dtype=x_data.dtype)\n",
        "        augmented_y_data = np.zeros((num_samples * num_angles), dtype=x_data.dtype)\n",
        "\n",
        "        for i in range(num_samples):\n",
        "            for j in range(num_angles):\n",
        "                # 어규멘테이션 데이터\n",
        "                augmented_x_data[i * num_angles + j] = np.roll(x_data[i], -j, axis=0)\n",
        "                augmented_y_data[i * num_angles + j] = y_data[i]\n",
        "\n",
        "        # 라벨 매핑 검증\n",
        "        for i in range(num_samples):\n",
        "            start_index = i * num_angles\n",
        "            end_index = (i + 1) * num_angles\n",
        "            labels = np.unique(augmented_y_data[start_index:end_index])\n",
        "            if labels[0] != y_data[i]:\n",
        "                print(\"Label mapping error for x_train[{}], y_train[{}].\".format(i, i))\n",
        "\n",
        "        # augmented_x_train의 배치사이즈를 기준으로 데이터 순서를 셔플\n",
        "        if shuffle == True:\n",
        "            shuffle_indices = np.random.permutation(augmented_x_data.shape[0])\n",
        "            augmented_x_data = augmented_x_data[shuffle_indices]\n",
        "            augmented_y_data = augmented_y_data[shuffle_indices]\n",
        "\n",
        "        print(\"\\t - Original to Augmented 'x_data / y_data' shape:\", x_data.shape, \"/\", y_data.shape, \"->\", augmented_x_data.shape, \"/\", augmented_y_data.shape)\n",
        "\n",
        "        return augmented_x_data, augmented_y_data, num_angles\n",
        "\n",
        "    def reshape_by_angle_interval(self, data, total_angle_num, angle_interval):\n",
        "        angle_num = (total_angle_num * 10) // angle_interval\n",
        "        angle_indices = np.linspace(0, total_angle_num - 1, angle_num, dtype=int) # 선택할 각도 인덱스 계산\n",
        "        new_data = np.zeros((data.shape[0], angle_num, *data.shape[2:]), dtype=data.dtype) # 새로운 데이터셋 생성\n",
        "\n",
        "        # 각도 인덱스를 이용하여 데이터 복사\n",
        "        for i, angle_idx in enumerate(angle_indices):\n",
        "            new_data[:, i, :] = data[:, angle_idx, :]\n",
        "\n",
        "        print(f\"\\t - X_Data reshaped by angle interval (angle interval - {angle_interval} degree) : \", new_data.shape)\n",
        "\n",
        "        return new_data\n",
        "    \n",
        "    def train_test_cnn(self, x_train, y_train, x_test, y_test, element, augment_num_angles):\n",
        "        input_data_shape = x_train.shape[1:]\n",
        "        cnn_model = self.create_cnn_model(input_data_shape)\n",
        "\n",
        "        print(\"CNN Model - RUNNING\".center(80, \"=\"))\n",
        "\n",
        "        # 학습 \n",
        "        lr_scheduler = LearningRateScheduler(self.exponential_decay)\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, restore_best_weights=True)        \n",
        "        cnn_model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.1), metrics=['accuracy'])\n",
        "        train_val_score = cnn_model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, batch_size=64, callbacks=[lr_scheduler, early_stopping]) \n",
        "        \n",
        "        # 학습된 모형 테스트 \n",
        "        if element == None: \n",
        "            test_score = cnn_model.evaluate(x_test, y_test)\n",
        "            test_accuracy = round(test_score[1]*100)\n",
        "            \n",
        "            print(f\"\\nTest Accuracy: {test_accuracy}%\")\n",
        "\n",
        "            return test_accuracy\n",
        "\n",
        "        else:\n",
        "            count = 0\n",
        "            _results = np.zeros(6)\n",
        "            x_test_all, y_test_all= self.split_y_test(x_test , y_test, element=element, augment_num_angles=augment_num_angles)\n",
        "\n",
        "            for num_1 in range(len(y_test_all)):\n",
        "                for num_2 in range(len(y_test_all[0])):\n",
        "                    test_score = cnn_model.evaluate(x_test_all[num_1][num_2], y_test_all[num_1][num_2])\n",
        "                    test_accuracy = round(test_score[1]*100)\n",
        "                    _results[count] = test_accuracy\n",
        "                    count+=1\n",
        "\n",
        "            mean_value = np.mean(_results[0:3])\n",
        "            cnn_result = np.round(np.insert(_results, 0, mean_value))\n",
        "\n",
        "            print(f\"Test Accuracy : {cnn_result[0]}%   ==>   ({', '.join([f'{acc}%' for acc in cnn_result[1:4]])}  /  {', '.join([f'{acc}%' for acc in cnn_result[4:7]])})\")\n",
        "\n",
        "            return cnn_result, train_val_score, cnn_model\n",
        "\n",
        "    def split_y_test(self, x_test, y_test, element, augment_num_angles):\n",
        "        if element != None:\n",
        "            indices_1 = [0, 1, 2, 9, 10, 11]; indices_2 = [3, 4, 5, 12, 13, 14]; indices_3 = [6, 7, 8, 15, 16, 17]\n",
        "            ind_1 = [0, 3, 6, 9, 12, 15]; ind_2 = [1, 4, 7, 10, 13, 16]; ind_3 = [2, 5, 8, 11, 14, 17]\n",
        "            aug_indices_list = [np.array([], dtype=int) for _ in range(3)]\n",
        "            aug_ind_list = [np.array([], dtype=int) for _ in range(3)]\n",
        "\n",
        "            for num, indices in enumerate([indices_1, indices_2, indices_3]):\n",
        "                for i in indices:\n",
        "                    aug_indices_list[num] = np.concatenate((aug_indices_list[num], np.arange(i * augment_num_angles, i * augment_num_angles + augment_num_angles)))\n",
        "            for num, ind in enumerate([ind_1, ind_2, ind_3]):\n",
        "                for i in ind:\n",
        "                    aug_ind_list[num] = np.concatenate((aug_ind_list[num], np.arange(i * augment_num_angles, i * augment_num_angles + augment_num_angles)))\n",
        "\n",
        "            x_test_1 = [x_test[aug_indices_list[0]], x_test[aug_indices_list[1]], x_test[aug_indices_list[2]]]\n",
        "            y_test_1 = [y_test[aug_indices_list[0]], y_test[aug_indices_list[1]], y_test[aug_indices_list[2]]]\n",
        "            x_test_2 = [x_test[aug_ind_list[0]], x_test[aug_ind_list[1]], x_test[aug_ind_list[2]]]\n",
        "            y_test_2 = [y_test[aug_ind_list[0]], y_test[aug_ind_list[1]], y_test[aug_ind_list[2]]]\n",
        "\n",
        "            x_test_all = [x_test_1, x_test_2]\n",
        "            y_test_all = [y_test_1, y_test_2]\n",
        "\n",
        "            return x_test_all, y_test_all\n",
        "\n",
        "    def exponential_decay(self, epoch):\n",
        "        initial_lr = 0.1; decay_rate = 0.1\n",
        "        lr = initial_lr * np.exp(-decay_rate * epoch)\n",
        "        return lr\n",
        "\n",
        "    def step_decay(self, epoch):\n",
        "        initial_lr = 0.1; drop_rate = 0.5; drop_epochs = 10\n",
        "        lr = initial_lr * (drop_rate ** (epoch // drop_epochs))\n",
        "        return lr\n",
        "\n",
        "    def create_cnn_model(self, input_data_shape):\n",
        "        cnn_model = Sequential()\n",
        "\n",
        "        cnn_model.add(Conv3D(32, kernel_size=(3, 3, 3), strides=(1, 1, 2), padding=\"same\", input_shape=input_data_shape, kernel_initializer=initializers.HeNormal(), data_format=\"channels_first\"))\n",
        "        cnn_model.add(BatchNormalization())\n",
        "        cnn_model.add(LeakyReLU(alpha=0.01))\n",
        "        cnn_model.add(Dropout(0.7))\n",
        "        cnn_model.add(MaxPooling3D(pool_size=(1, 1, 5), data_format=\"channels_first\"))\n",
        "\n",
        "        cnn_model.add(Flatten())\n",
        "\n",
        "        cnn_model.add(Dense(32, kernel_initializer=initializers.HeNormal()))\n",
        "        cnn_model.add(BatchNormalization())\n",
        "        cnn_model.add(LeakyReLU(alpha=0.01))\n",
        "        cnn_model.add(Dropout(0.7))\n",
        "\n",
        "        cnn_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        return cnn_model"
      ],
      "metadata": {
        "id": "pi1Nr8wvhhAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the CNN Model - Setup"
      ],
      "metadata": {
        "id": "nLN6gT2LMv02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_dir_path = []\n",
        "\n",
        "dir_paths = [os.path.join(\"/content/drive/MyDrive/Colab Notebooks/DTX/merged_sample3/all/angle360_step10\", feature) for feature in [\"distance\", \"height\", \"type\"]]\n",
        "\n",
        "# 기본 36개의 각도를 다 사용하는 angle_interval = 10\n",
        "angle_interval = 10\n",
        "\n",
        "split_accuracy = True\n",
        "augmentation = True\n",
        "total_angle_num = 36"
      ],
      "metadata": {
        "id": "xZXdDnFoc2Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dir_path in dir_paths :\n",
        "    subdir_name = next(os.walk(dir_path))[1]\n",
        "    for name in subdir_name:\n",
        "        subdir_path = os.path.join(dir_path, name)\n",
        "        all_dir_path.append(subdir_path)\n",
        "\n",
        "# 컬럼명만 있는 데이터프레임 생성\n",
        "if split_accuracy==True:\n",
        "    result_df = pd.DataFrame(columns=['Train/Test Set Composition', 'CNN Accuracy', \"Accuracy_1-1\", \"Accuracy_1-2\", \"Accuracy_1-3\", \"Accuracy_2-1\", \"Accuracy_2-2\", \"Accuracy_2-3\"])\n",
        "else:\n",
        "    result_df = pd.DataFrame(columns=['Train/Test Set Composition', 'CNN Accuracy'])\n",
        "\n",
        "# 빈 행 추가\n",
        "empty_row = pd.DataFrame([{}], columns=result_df.columns)\n",
        "result_df = pd.concat([result_df, empty_row], ignore_index=True)"
      ],
      "metadata": {
        "id": "ppo1JLsgdWLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the CNN Model"
      ],
      "metadata": {
        "id": "vvsqovNmUPz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iter_num = 7  # 호호\n",
        "train_val_score_list = [None]*iter_num\n",
        "model_list = [None]*iter_num\n",
        "\n",
        "for num, dir_path in enumerate(all_dir_path):\n",
        "    if (num+1) == iter_num: pass # 하나씩 저장\n",
        "    else : continue\n",
        "\n",
        "    (train_path, test_path, train_test_set_composition) = train_test_dir_path(dir_path)\n",
        "\n",
        "    print(f\"Start ({num+1} / {len(all_dir_path)})     :       {train_test_set_composition}    ({dir_path})\")\n",
        "    start_time = time.time()\n",
        "    cnn = cnn_clf(train_path, test_path)\n",
        "\n",
        "    if split_accuracy == True:\n",
        "        element = train_test_set_composition.split('(')[0]\n",
        "        cnn_result, train_val_score_list[num], model_list[num] = cnn.main(augmentation=augmentation, element=element, total_angle_num=total_angle_num, angle_interval=angle_interval)\n",
        "    else :\n",
        "        element = None\n",
        "        cnnr_result, train_val_score_list[num], model_list[num] = cnn.main(augmentation=augmentation, element=element, total_angle_num=total_angle_num, angle_interval=angle_interval)\n",
        "\n",
        "    # 새로운 값 추가\n",
        "    if split_accuracy == True:\n",
        "        new_values = [train_test_set_composition, cnn_result[0], cnn_result[1], cnn_result[2], cnn_result[3], cnn_result[4], cnn_result[5], cnn_result[6]]\n",
        "        result_df.loc[result_df.index[-1] + 1] = new_values\n",
        "    else:\n",
        "        new_values = [train_test_set_composition, cnn_result]\n",
        "        result_df.loc[result_df.index[-1] + 1] = new_values\n",
        "\n",
        "    # 빈 행 추가\n",
        "    if (num - 2) % 3 == 0:\n",
        "        empty_row = pd.DataFrame([{}], columns=result_df.columns)\n",
        "        result_df = pd.concat([result_df, empty_row], ignore_index=True)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    minutes = int(elapsed_time // 60)\n",
        "    seconds = int(elapsed_time % 60)\n",
        "    print(f\"Time elapsed: {minutes} minutes {seconds} seconds\\n\")\n",
        "    print(\"\\n\")\n",
        "    #break"
      ],
      "metadata": {
        "id": "hLg5_k-udmUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델 결과 그래프 출력 : Test Accuracy : 72.0%   ==>   (100.0%, 67.0%, 50.0%  /  83.0%, 67.0%, 67.0%)\n",
        "plot_loss_and_accuracy(train_val_score_list[iter_num-1].history['loss'], train_val_score_list[iter_num-1].history['val_loss'],\n",
        "                       train_val_score_list[iter_num-1].history['accuracy'], train_val_score_list[iter_num-1].history['val_accuracy'], 'CNN')"
      ],
      "metadata": {
        "id": "PhLdlkBrXiTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the Pretrained Model, Loss, Accuracy"
      ],
      "metadata": {
        "id": "jHuKgv35qeJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save_model_path = '/content/drive/MyDrive/Colab Notebooks/DTX/pretrained_model_weights/all/angle360_step10/distance/distance(3&5-1)' #호호\n",
        "# save_model_path = '/content/drive/MyDrive/Colab Notebooks/DTX/pretrained_model_weights/all/angle360_step10/height/height(2&4-0)' #호호\n",
        "save_model_path = '/content/drive/MyDrive/Colab Notebooks/DTX/pretrained_model_weights/all/angle360_step10/type/type(1.5&2-4)' #호호\n",
        "\n",
        "# 테스트 데이터 정확도 저장\n",
        "result_df.to_excel('sample_result_all.xlsx', index=False)\n",
        "files.download('sample_result_all.xlsx')\n",
        "\n",
        "# 학습 완료된 모델 가중치 저장\n",
        "for i, model in enumerate(model_list):\n",
        "    if i==(iter_num-1): # 하나씩 저장\n",
        "        model.save(f'{save_model_path}/model{i}.h5')\n",
        "\n",
        "# 학습 완료된 모델의 학습과정(loss & accuracy) 저장\n",
        "for i, train_val_score in enumerate(train_val_score_list):\n",
        "    if i==(iter_num-1): # 하나씩 저장\n",
        "        loss_values = train_val_score.history['loss']\n",
        "        accuracy_values = train_val_score.history['accuracy']\n",
        "        val_loss_values = train_val_score.history['val_loss']\n",
        "        val_accuracy_values = train_val_score.history['val_accuracy']\n",
        "\n",
        "        np.savetxt(f'{save_model_path}/train_loss{i}.txt', loss_values)\n",
        "        np.savetxt(f'{save_model_path}/train_accuracy{i}.txt', accuracy_values)\n",
        "        np.savetxt(f'{save_model_path}/val_loss{i}.txt', val_loss_values)\n",
        "        np.savetxt(f'{save_model_path}/val_accuracy{i}.txt', val_accuracy_values)"
      ],
      "metadata": {
        "id": "yduB4BsvdpHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save_model_path = '/content/drive/MyDrive/Colab Notebooks/DTX/pretrained_model_weights/ALL/angle360_step10/distance/distance(1&3-5)'\n",
        "\n",
        "# 손실(loss) 값을 파일로부터 불러오기\n",
        "\n",
        "train_loss_file_path = f'{save_model_path}/train_loss{(iter_num-1)}.txt'\n",
        "train_loss_v = np.loadtxt(train_loss_file_path)\n",
        "val_loss_file_path = f'{save_model_path}/val_loss{(iter_num-1)}.txt'\n",
        "val_loss_v = np.loadtxt(val_loss_file_path)\n",
        "\n",
        "# 정확도(accuracy) 값을 파일로부터 불러오기\n",
        "train_accuracy_file_path = f'{save_model_path}/train_accuracy{(iter_num-1)}.txt'\n",
        "train_acc_v = np.loadtxt(train_accuracy_file_path)\n",
        "val_accuracy_file_path = f'{save_model_path}/val_accuracy{(iter_num-1)}.txt'\n",
        "val_acc_v = np.loadtxt(val_accuracy_file_path)\n",
        "\n",
        "# CNN 모델 결과 그래프 출력\n",
        "plot_loss_and_accuracy(train_loss_v, val_loss_v,\n",
        "                       train_acc_v, val_acc_v, 'CNN')"
      ],
      "metadata": {
        "id": "Q9RaTXyQmZYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test : Defining the Pretrainded CNN Classifier Class "
      ],
      "metadata": {
        "id": "JB1XshTFP58M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class pretrained_cnn_clf:\n",
        "    def __init__(self, train_dir_path, test_dir_path, pretrained_cnn_model):\n",
        "        self.train_dir_path = train_dir_path\n",
        "        self.test_dir_path = test_dir_path\n",
        "        self.cnn_model = pretrained_cnn_model\n",
        "\n",
        "    def main(self, augmentation, total_angle_num, angle_interval, element):\n",
        "        x_train, y_train = self.load_dataset(dir_path=self.train_dir_path, mode=\"TRAIN\", shuffle=True)\n",
        "        x_test, y_test = self.load_dataset(dir_path=self.test_dir_path, mode=\"TEST\", shuffle=False)\n",
        "\n",
        "        x_train = self.feature_scaling(x_train, norm=False, std=True, with_mean=True)\n",
        "        x_test = self.feature_scaling(x_test, norm=False, std=True, with_mean=True)\n",
        "\n",
        "        if augmentation == True:\n",
        "            x_train, y_train, augment_num_angles = self.augment_data(x_train, y_train, shuffle=True)\n",
        "            x_test, y_test, augment_num_angles = self.augment_data(x_test, y_test, shuffle=False)\n",
        "        else:\n",
        "            augment_num_angles = 1\n",
        "\n",
        "        if angle_interval != 10:\n",
        "            x_train = self.reshape_by_angle_interval(x_train, total_angle_num=total_angle_num, angle_interval=angle_interval)\n",
        "            x_test = self.reshape_by_angle_interval(x_test, total_angle_num=total_angle_num, angle_interval=angle_interval)\n",
        "\n",
        "        cnn_result = self.train_test_cnn(x_train, y_train, x_test, y_test, element, augment_num_angles)\n",
        "\n",
        "        return cnn_result\n",
        "\n",
        "    def load_dataset(self, dir_path, mode, shuffle):\n",
        "        x_train_list = []\n",
        "        y_train = np.array([])\n",
        "\n",
        "        if shuffle == True:\n",
        "            random.seed(42)\n",
        "            sample_size = len(os.listdir(dir_path))\n",
        "            population = list(range(sample_size))\n",
        "            samples_num = random.sample(population, sample_size)\n",
        "        else :\n",
        "            sample_size = len(os.listdir(dir_path))\n",
        "            samples_num = list(range(sample_size))\n",
        "\n",
        "        for num in samples_num:\n",
        "            loaded = np.load(f\"{dir_path}/{mode}_({num}).npz\")\n",
        "            data = loaded[\"data\"]\n",
        "            label = loaded[\"label\"]\n",
        "\n",
        "            x_train_list.append(data)\n",
        "            y_train = np.concatenate([y_train, label])\n",
        "\n",
        "        x_train = np.stack(x_train_list, axis=0).astype(np.float32)\n",
        "        y_train = y_train.astype(np.float32)\n",
        "\n",
        "        return x_train, y_train\n",
        "\n",
        "    def feature_scaling(self, data, norm, std, with_mean):\n",
        "        if std == True:\n",
        "            if with_mean==True:\n",
        "                mean = np.mean(data, axis=tuple(range(data.ndim)), keepdims=True)\n",
        "                std = np.std(data, axis=tuple(range(data.ndim)), keepdims=True)\n",
        "                data = (data - mean) / std\n",
        "            else:\n",
        "                std = np.std(data, axis=tuple(range(data.ndim)), keepdims=True)\n",
        "                data = data / std\n",
        "        elif norm == True:\n",
        "            min = data.min()\n",
        "            max = data.max()\n",
        "            data = (data - min) / (max - min)\n",
        "\n",
        "        return data\n",
        "\n",
        "    def augment_data(self, x_data, y_data, shuffle):\n",
        "        num_samples = x_data.shape[0]  # 배치 사이즈\n",
        "        num_angles = x_data.shape[1]  # 각도의 개수\n",
        "\n",
        "        # 어규멘테이션된 데이터를 저장할 변수 초기화\n",
        "        augmented_x_data = np.zeros((num_samples * num_angles, *x_data.shape[1:]), dtype=x_data.dtype)\n",
        "        augmented_y_data = np.zeros((num_samples * num_angles), dtype=x_data.dtype)\n",
        "\n",
        "        for i in range(num_samples):\n",
        "            for j in range(num_angles):\n",
        "                # 어규멘테이션 데이터\n",
        "                augmented_x_data[i * num_angles + j] = np.roll(x_data[i], -j, axis=0)\n",
        "                augmented_y_data[i * num_angles + j] = y_data[i]\n",
        "\n",
        "        # 라벨 매핑 검증\n",
        "        for i in range(num_samples):\n",
        "            start_index = i * num_angles\n",
        "            end_index = (i + 1) * num_angles\n",
        "            labels = np.unique(augmented_y_data[start_index:end_index])\n",
        "            if labels[0] != y_data[i]:\n",
        "                print(\"Label mapping error for x_train[{}], y_train[{}].\".format(i, i))\n",
        "\n",
        "        # augmented_x_train의 배치사이즈를 기준으로 데이터 순서를 셔플\n",
        "        if shuffle == True:\n",
        "            shuffle_indices = np.random.permutation(augmented_x_data.shape[0])\n",
        "            augmented_x_data = augmented_x_data[shuffle_indices]\n",
        "            augmented_y_data = augmented_y_data[shuffle_indices]\n",
        "\n",
        "        print(\"\\t - Original to Augmented 'x_data / y_data' shape:\", x_data.shape, \"/\", y_data.shape, \"->\", augmented_x_data.shape, \"/\", augmented_y_data.shape)\n",
        "\n",
        "        return augmented_x_data, augmented_y_data, num_angles\n",
        "\n",
        "    def reshape_by_angle_interval(self, data, total_angle_num, angle_interval):\n",
        "        angle_num = (total_angle_num * 10) // angle_interval\n",
        "        angle_indices = np.linspace(0, total_angle_num - 1, angle_num, dtype=int) # 선택할 각도 인덱스 계산\n",
        "        new_data = np.zeros((data.shape[0], angle_num, *data.shape[2:]), dtype=data.dtype) # 새로운 데이터셋 생성\n",
        "\n",
        "        # 각도 인덱스를 이용하여 데이터 복사\n",
        "        for i, angle_idx in enumerate(angle_indices):\n",
        "            new_data[:, i, :] = data[:, angle_idx, :]\n",
        "\n",
        "        print(f\"\\t - X_Data reshaped by angle interval (angle interval - {angle_interval} degree) : \", new_data.shape)\n",
        "\n",
        "        return new_data\n",
        "    \n",
        "    def train_test_cnn(self, x_train, y_train, x_test, y_test, element, augment_num_angles):\n",
        "\n",
        "        print(\"Test Pretrained CNN Model - RUNNING\".center(80, \"=\"))\n",
        "        \n",
        "        # 학습된 모형 테스트 \n",
        "        if element == None: \n",
        "            test_score = self.cnn_model.evaluate(x_test, y_test)\n",
        "            test_accuracy = round(test_score[1]*100)\n",
        "            \n",
        "            print(f\"\\nTest Accuracy: {test_accuracy}%\")\n",
        "\n",
        "            return test_accuracy\n",
        "\n",
        "        else:\n",
        "            count = 0\n",
        "            _results = np.zeros(6)\n",
        "            x_test_all, y_test_all= self.split_y_test(x_test , y_test, element=element, augment_num_angles=augment_num_angles)\n",
        "\n",
        "            for num_1 in range(len(y_test_all)):\n",
        "                for num_2 in range(len(y_test_all[0])):\n",
        "                    test_score = self.cnn_model.evaluate(x_test_all[num_1][num_2], y_test_all[num_1][num_2])\n",
        "                    test_accuracy = round(test_score[1]*100)\n",
        "                    _results[count] = test_accuracy\n",
        "                    count+=1\n",
        "\n",
        "            mean_value = np.mean(_results[0:3])\n",
        "            cnn_result = np.round(np.insert(_results, 0, mean_value))\n",
        "\n",
        "            print(f\"Test Accuracy : {cnn_result[0]}%   ==>   ({', '.join([f'{acc}%' for acc in cnn_result[1:4]])}  /  {', '.join([f'{acc}%' for acc in cnn_result[4:7]])})\")\n",
        "\n",
        "            return cnn_result\n",
        "\n",
        "    def split_y_test(self, x_test, y_test, element, augment_num_angles):\n",
        "        if element != None:\n",
        "            indices_1 = [0, 1, 2, 9, 10, 11]; indices_2 = [3, 4, 5, 12, 13, 14]; indices_3 = [6, 7, 8, 15, 16, 17]\n",
        "            ind_1 = [0, 3, 6, 9, 12, 15]; ind_2 = [1, 4, 7, 10, 13, 16]; ind_3 = [2, 5, 8, 11, 14, 17]\n",
        "            aug_indices_list = [np.array([], dtype=int) for _ in range(3)]\n",
        "            aug_ind_list = [np.array([], dtype=int) for _ in range(3)]\n",
        "\n",
        "            for num, indices in enumerate([indices_1, indices_2, indices_3]):\n",
        "                for i in indices:\n",
        "                    aug_indices_list[num] = np.concatenate((aug_indices_list[num], np.arange(i * augment_num_angles, i * augment_num_angles + augment_num_angles)))\n",
        "            for num, ind in enumerate([ind_1, ind_2, ind_3]):\n",
        "                for i in ind:\n",
        "                    aug_ind_list[num] = np.concatenate((aug_ind_list[num], np.arange(i * augment_num_angles, i * augment_num_angles + augment_num_angles)))\n",
        "\n",
        "            x_test_1 = [x_test[aug_indices_list[0]], x_test[aug_indices_list[1]], x_test[aug_indices_list[2]]]\n",
        "            y_test_1 = [y_test[aug_indices_list[0]], y_test[aug_indices_list[1]], y_test[aug_indices_list[2]]]\n",
        "            x_test_2 = [x_test[aug_ind_list[0]], x_test[aug_ind_list[1]], x_test[aug_ind_list[2]]]\n",
        "            y_test_2 = [y_test[aug_ind_list[0]], y_test[aug_ind_list[1]], y_test[aug_ind_list[2]]]\n",
        "\n",
        "            x_test_all = [x_test_1, x_test_2]\n",
        "            y_test_all = [y_test_1, y_test_2]\n",
        "\n",
        "            return x_test_all, y_test_all"
      ],
      "metadata": {
        "id": "SAkT1O-mP3KK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test : Pretrainded CNN Model"
      ],
      "metadata": {
        "id": "wDfG9A3eXqMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 36개의 각도를 다 사용하는 angle_interval = 10\n",
        "pre_angle_interval = 10\n",
        "\n",
        "pre_split_accuracy = True\n",
        "pre_augmentation = True\n",
        "pre_total_angle_num = 36\n",
        "\n",
        "# 저장된 모델 불러오기\n",
        "\n",
        "loaded_model = keras.models.load_model(f'{save_model_path}/model{iter_num-1}.h5')\n",
        "pretrained_cnn = pretrained_cnn_clf(pre_train_path, pre_test_path, pretrained_cnn_model=loaded_model)\n",
        "\n",
        "# pre_dir_path = '/content/drive/MyDrive/Colab Notebooks/DTX/merged_sample3/all/angle360_step10/distance/distance(3&5-1)' #호호\n",
        "# pre_dir_path = '/content/drive/MyDrive/Colab Notebooks/DTX/merged_sample3/all/angle360_step10/height/height(0&4-2)' #호호\n",
        "pre_dir_path = '/content/drive/MyDrive/Colab Notebooks/DTX/merged_sample3/all/angle360_step10/type/type(1.5&2-4)' #호호\n",
        "\n",
        "(pre_train_path, pre_test_path, pre_train_test_set_composition) = train_test_dir_path(pre_dir_path)\n",
        "\n",
        "if split_accuracy == True:\n",
        "    pre_element = pre_train_test_set_composition.split('(')[0]\n",
        "    pretrained_cnn.main(augmentation=pre_augmentation, element=pre_element, total_angle_num=pre_total_angle_num, angle_interval=pre_angle_interval)\n",
        "else :\n",
        "    pre_element = None\n",
        "    pretrained_cnn.main(augmentation=pre_augmentation, element=pre_element, total_angle_num=pre_total_angle_num, angle_interval=pre_angle_interval)"
      ],
      "metadata": {
        "id": "tp4vuTxSN62a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}